4.1 Jeu de Données et Prétraitement
Le projet utilise le jeu de données CICIDS2017, qui contient environ 2,8 millions d'enregistrements de trafic réseau capturés sur cinq jours. Ce dataset inclut du trafic bénin ainsi que diverses attaques : Brute Force, DoS (Slowloris, Slowhttptest, Hulk, GoldenEye), Heartbleed, Web Attack, Infiltration, Botnet et DDoS.
Le prétraitement des données comprend plusieurs étapes. Premièrement, le nettoyage des données avec la suppression des valeurs infinies et manquantes, représentant environ 0,1% du dataset. Deuxièmement, la sélection de 20 caractéristiques les plus discriminantes basée sur l'importance des features d'un modèle préliminaire, incluant notamment : Flow Duration, Total Fwd Packets, Total Backward Packets, Flow Bytes/s, Flow Packets/s, et diverses statistiques sur les tailles de paquets.
La normalisation utilise StandardScaler pour centrer et réduire les features numériques. L'encodage transforme les labels multi-classes en classification binaire (BENIGN → 0, toutes les attaques → 1). Finalement, la division du dataset se fait avec 80% pour l'entraînement et 20% pour le test, avec stratification pour maintenir la distribution des classes.
4.2 Entraînement du Modèle
Le choix s'est porté sur un classificateur Random Forest pour plusieurs raisons : sa robustesse face au sur-apprentissage grâce à l'ensemble d'arbres, sa capacité à gérer des features de différentes échelles, son interprétabilité via l'importance des caractéristiques, et ses performances reconnues sur les tâches de détection d'intrusions dans la littérature.
L'optimisation des hyperparamètres a été réalisée via GridSearchCV avec validation croisée 5-fold. Les paramètres optimaux identifiés sont : n_estimators=200, max_depth=30, min_samples_split=5, min_samples_leaf=2, et class_weight='balanced' pour gérer le déséquilibre des classes.
Le modèle entraîné et le pipeline de prétraitement (StandardScaler) sont sérialisés ensemble avec joblib dans le fichier model.joblib, garantissant la cohérence entre l'entraînement et l'inférence. L'entraînement complet, incluant la recherche d'hyperparamètres, prend environ 45 minutes sur un CPU 8 cœurs.
